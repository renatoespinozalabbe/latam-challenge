{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as. Debe incluir las siguientes funciones:\n",
    "```python\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "```\n",
    "```python\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "```\n",
    "```python\n",
    "Returns: \n",
    "[(datetime.date(1999, 11, 15), \"LATAM321\"), (datetime.date(1999, 7, 15), \"LATAM_CHI\"), ...]\n",
    "```\n",
    "## PREGUNTA 1 - TIME (q1_time)\n",
    "Para desarrollar la soluci√≥n a este problema se utilizar√° una soluci√≥n cloud basada en Google Cloud Platform. La funci√≥n contendr√° el proceso de ETL para llevar los datos desde el archivo json local hacia Google Cloud Storage y posteriormente modelar esa data en una tabla de bigquery que permita realizar consultas de manera r√°pida y eficiente.\n",
    "### ETL\n",
    "El proceso de extracci√≥n, transformaci√≥n y carga de los archivos en GCP permite llevar los archivos a una plataforma de performance r√°pida y efectiva.\n",
    "#### Credenciales\n",
    "Este desarrollo se realizar√° utilizando Google Cloud, por lo que se crea un proyecto en GCP llamado \"project-latam-challenge\". En este proyecto se crea una service account llamada \"sa-etl-latam-challenge\" que ser√° utilizada para realizar la carga de datos.\n",
    "```python\n",
    "import os\n",
    "\n",
    "# Ruta a archivo de credenciales JSON de Google Cloud\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../credentials/project-latam-challenge-749ce1a96052.json\"\n",
    "```\n",
    "#### Carga en Dataframe\n",
    "Se carga en un dataframe el [archivo](https://drive.google.com/file/d/1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis/view?usp=sharing) json declarado como parte del challenge.\n",
    "```python\n",
    "    # Leer el archivo CSV en un DataFrame\n",
    "    df = pd.read_json(file_path,lines=True)\n",
    "```\n",
    "#### Carga de dataframe en GCP\n",
    "##### Carga de archivo en Google Cloud Storage (GCS)\n",
    "Usando Google Cloud SDK se crea un bucket llamado 'bucket-project-latam-challenge-q1-time' en el proyecto 'project-latam-challenge' y se carga el archivo directamente a dicho bucket.\n",
    "```python\n",
    "    # Se define funci√≥n que permite cargar un archivo en un bucket de Google Cloud Storage\n",
    "    def create_bucket_and_upload_file(project_id, bucket_name, file_path, destination_blob_name):\n",
    "        # Inicializar el cliente de almacenamiento\n",
    "        storage_client = storage.Client(project=project_id)\n",
    "        \n",
    "        # Verificar si el bucket ya existe\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        if not bucket.exists():\n",
    "            # Crear un nuevo bucket con la ubicaci√≥n especificada\n",
    "            new_bucket = storage_client.create_bucket(bucket, location=\"US\")\n",
    "            print(f'Bucket {bucket_name} created in location US.')\n",
    "        else:\n",
    "            print(f'Bucket {bucket_name} already exists.')\n",
    "            new_bucket = bucket\n",
    "        \n",
    "        # Subir el archivo al bucket\n",
    "        blob = new_bucket.blob(destination_blob_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        print(f'File {file_path} uploaded to {bucket_name}/{destination_blob_name}.')\n",
    "```\n",
    "##### Configuraci√≥n de carga\n",
    "```python\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Par√°metros\n",
    "project_id = 'project-latam-challenge'\n",
    "dataset_id = 'twitter_data'\n",
    "table_id = 'farmers_protest_tweets_2021'\n",
    "```\n",
    "##### Declaraci√≥n de schema\n",
    "Se declara explicitamente la estructura del esquema con la data correspondiente, esto permitir√° evitar errores en los tipos de dato al cargar la data en Bigquery.\n",
    "Por motivos de claridad al momento de leer el markdown, se omite el schema que se puede encontrar en el archivo q1_time.py .\n",
    "##### Proceso de creaci√≥n de tabla en bigquery\n",
    "```python\n",
    "    # Se define funci√≥n que crea tabla de bigquery a partir de archivo almacenado en GCS\n",
    "    def load_data_from_gcs_to_bigquery(uri, table_id):\n",
    "        # Inicializa el cliente de BigQuery\n",
    "        client = bigquery.Client()\n",
    "\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            schema=schema,\n",
    "            source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "            max_bad_records=0,  # No permitir registros malos antes de fallar\n",
    "            time_partitioning=bigquery.TimePartitioning(\n",
    "                type_=bigquery.TimePartitioningType.DAY,\n",
    "                field=\"date\"  # Campo de partici√≥n\n",
    "            )\n",
    "        )\n",
    "\n",
    "        load_job = client.load_table_from_uri(\n",
    "            uri, table_id, job_config=job_config\n",
    "        )\n",
    "\n",
    "        print(f'Starting job {load_job.job_id}')\n",
    "        load_job.result()\n",
    "        print(f'Job finished.')\n",
    "\n",
    "        destination_table = client.get_table(table_id)\n",
    "        print(f'Loaded {destination_table.num_rows} rows.')\n",
    "```\n",
    "##### An√°lisis\n",
    "Se define funci√≥n que permite ejecutar la consulta en bigquery.\n",
    "\n",
    "```python\n",
    "    # Se define funci√≥n para ejecutar una consulta en BigQuery\n",
    "    def run_bigquery_query(query: str):\n",
    "        client = get_bigquery_client()\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "        return results\n",
    "```\n",
    "Se define la query SQL que permite ejecutar la consulta en bigquery.\n",
    "```python\n",
    "    query = \"\"\"\n",
    "        WITH TEMP_DATA_001 AS \n",
    "        (\n",
    "        -- Se crea la tabla temporal s√≥lo con los campos necesarios para realizar ambos c√°lculos, tanto por fecha como por usuario\n",
    "        SELECT DATE(date) AS fecha,\n",
    "            id,\n",
    "            user.username AS username\n",
    "        FROM `project-latam-challenge.twitter_data.farmers_protest_tweets_2021` \n",
    "        WHERE DATE(date) IS NOT NULL\n",
    "        ), TEMP_DATE_001 AS \n",
    "        (\n",
    "        -- Se realiza el c√°lculo de la cantidad de tweets por fecha\n",
    "        SELECT fecha,\n",
    "            COUNT(DISTINCT id) AS tweet_qty\n",
    "        FROM TEMP_DATA_001\n",
    "        GROUP BY fecha\n",
    "        ), TEMP_DATE_002 AS \n",
    "        (\n",
    "        -- Se realiza el ranking de tweets ordenados descendentemente por cantidad de tweets y aleatoriamente\n",
    "        SELECT A.*,\n",
    "            RANK() OVER(ORDER BY tweet_qty DESC, RAND()) AS ranking_tweet \n",
    "        FROM TEMP_DATE_001 A\n",
    "        ), TEMP_USER_001 AS \n",
    "        (\n",
    "        -- Se realiza el c√°lculo de la cantidad de tweets por usuario y fecha\n",
    "        SELECT fecha,\n",
    "            username,\n",
    "            COUNT(DISTINCT id) AS tweet_qty\n",
    "        FROM TEMP_DATA_001\n",
    "        GROUP BY fecha, username\n",
    "        ), TEMP_USER_002 AS \n",
    "        -- Se realiza el ranking de usuarios por fecha, ordenados descendentemente por cantidad de tweets y aleatoriamente\n",
    "        (\n",
    "        SELECT A.*,\n",
    "            RANK() OVER(PARTITION BY fecha ORDER BY tweet_qty DESC, RAND()) AS ranking_user\n",
    "        FROM TEMP_USER_001 A\n",
    "        ), TEMP_USER_003 AS \n",
    "        (\n",
    "        -- Se seleccionan los usuarios con ranking 1, es decir, aquellos que m√°s tweets hicieron por d√≠a\n",
    "        SELECT A.*\n",
    "        FROM TEMP_USER_002 A\n",
    "        WHERE ranking_user=1\n",
    "        )\n",
    "        -- Se filtra la tabla temporal de tweets por fecha, seleccionando s√≥lo los d√≠as que se encuentran en el top 10\n",
    "        SELECT A.fecha,\n",
    "            B.username\n",
    "        FROM TEMP_DATE_002 A\n",
    "        LEFT JOIN TEMP_USER_003 B\n",
    "        ON A.fecha=B.fecha \n",
    "        WHERE A.ranking_tweet<=10\n",
    "        ORDER BY ranking_tweet\n",
    "        \"\"\"\n",
    "    \n",
    "    results = run_bigquery_query(query)\n",
    "    return [(row.fecha, row.username) for row in results]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso q1_time...\n",
      "Leyendo archivo JSON\n",
      "Creando bucket y subiendo archivo\n",
      "Bucket bucket-project-latam-challenge-q1-time created in location US.\n",
      "File farmers-protest-tweets-2021-2-4.json uploaded to bucket-project-latam-challenge-q1-time/farmers-protest-tweets-2021-2-4.json.\n",
      "Cargando datos a BigQuery\n",
      "Starting job 22e9f6c9-c732-4439-b44f-a688290fc0ea\n",
      "Job finished.\n",
      "Loaded 117407 rows.\n",
      "Ejecutando query\n",
      "Resultados:\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "Tiempo de ejecuci√≥n: 59.299320936203 segundos\n",
      "Uso m√°ximo de memoria: 2244.50390625 MiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from q1_time import q1_time\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../credentials/project-latam-challenge-749ce1a96052.json\"\n",
    "\n",
    "# Funci√≥n para medir el tiempo y la memoria de q1_time\n",
    "def measure_q1_time(file_path):\n",
    "    start_time = time.time()\n",
    "    mem_usage, result = memory_usage((q1_time, (file_path,)), retval=True, max_usage=True)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    return result, duration, mem_usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando proceso q1_time...\")\n",
    "    top_10_dates, duration, mem_usage = measure_q1_time(file_path)\n",
    "    print(\"Resultados:\")\n",
    "    print(top_10_dates)\n",
    "    print(f\"Tiempo de ejecuci√≥n: {duration} segundos\")\n",
    "    print(f\"Uso m√°ximo de memoria: {mem_usage} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREGUNTA 1 - MEMORY\n",
    "Se propone generar un proceso an√°logo al anteriormente realizado para la versi√≥n time, pero con una carga parcelada de forma que utilice menos memoria local y se ejecute con menor necesidad de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Los top 10 emojis m√°s usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
    "```python\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "```\n",
    "```python\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "```\n",
    "```python\n",
    "Returns: \n",
    "[(\"‚úàÔ∏è\", 6856), (\"‚ù§Ô∏è\", 5876), ...]\n",
    "```\n",
    "## PREGUNTA 2 - TIME (q2_time)\n",
    "Para desarrollar la soluci√≥n a este problema se utilizar√° una soluci√≥n cloud basada en Google Cloud Platform. La funci√≥n contendr√° el proceso de ETL para llevar los datos desde el archivo json local hacia Google Cloud Storage y posteriormente modelar esa data en una tabla de bigquery que permita realizar consultas de manera r√°pida y eficiente.\n",
    "### ETL\n",
    "El proceso de extracci√≥n, transformaci√≥n y carga de los archivos en GCP permite llevar los archivos a una plataforma de performance r√°pida y efectiva.\n",
    "#### Credenciales\n",
    "Este desarrollo se realizar√° utilizando Google Cloud, por lo que se crea un proyecto en GCP llamado \"project-latam-challenge\". En este proyecto se crea una service account llamada \"sa-etl-latam-challenge\" que ser√° utilizada para realizar la carga de datos.\n",
    "```python\n",
    "import os\n",
    "\n",
    "# Ruta a archivo de credenciales JSON de Google Cloud\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../credentials/project-latam-challenge-749ce1a96052.json\"\n",
    "```\n",
    "#### Carga en Dataframe\n",
    "Se carga en un dataframe el [archivo](https://drive.google.com/file/d/1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis/view?usp=sharing) json declarado como parte del challenge.\n",
    "```python\n",
    "    # Leer el archivo CSV en un DataFrame\n",
    "    df = pd.read_json(file_path,lines=True)\n",
    "```\n",
    "#### Carga de dataframe en GCP\n",
    "##### Carga de archivo en Google Cloud Storage (GCS)\n",
    "Usando Google Cloud SDK se crea un bucket llamado 'bucket-project-latam-challenge-q1-time' en el proyecto 'project-latam-challenge' y se carga el archivo directamente a dicho bucket.\n",
    "```python\n",
    "    # Se define funci√≥n que permite cargar un archivo en un bucket de Google Cloud Storage\n",
    "    def create_bucket_and_upload_file(project_id, bucket_name, file_path, destination_blob_name):\n",
    "        # Inicializar el cliente de almacenamiento\n",
    "        storage_client = storage.Client(project=project_id)\n",
    "        \n",
    "        # Verificar si el bucket ya existe\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        if not bucket.exists():\n",
    "            # Crear un nuevo bucket con la ubicaci√≥n especificada\n",
    "            new_bucket = storage_client.create_bucket(bucket, location=\"US\")\n",
    "            print(f'Bucket {bucket_name} created in location US.')\n",
    "        else:\n",
    "            print(f'Bucket {bucket_name} already exists.')\n",
    "            new_bucket = bucket\n",
    "        \n",
    "        # Subir el archivo al bucket\n",
    "        blob = new_bucket.blob(destination_blob_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        print(f'File {file_path} uploaded to {bucket_name}/{destination_blob_name}.')\n",
    "```\n",
    "##### Configuraci√≥n de carga\n",
    "```python\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Par√°metros\n",
    "project_id = 'project-latam-challenge'\n",
    "dataset_id = 'twitter_data'\n",
    "table_id = 'farmers_protest_tweets_2021'\n",
    "```\n",
    "##### Declaraci√≥n de schema\n",
    "Se declara explicitamente la estructura del esquema con la data correspondiente, esto permitir√° evitar errores en los tipos de dato al cargar la data en Bigquery.\n",
    "Por motivos de claridad al momento de leer el markdown, se omite el schema que se puede encontrar en el archivo q1_time.py .\n",
    "##### Proceso de creaci√≥n de tabla en bigquery\n",
    "```python\n",
    "    # Se define funci√≥n que crea tabla de bigquery a partir de archivo almacenado en GCS\n",
    "    def load_data_from_gcs_to_bigquery(uri, table_id):\n",
    "        # Inicializa el cliente de BigQuery\n",
    "        client = bigquery.Client()\n",
    "\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            schema=schema,\n",
    "            source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "            max_bad_records=0,  # No permitir registros malos antes de fallar\n",
    "            time_partitioning=bigquery.TimePartitioning(\n",
    "                type_=bigquery.TimePartitioningType.DAY,\n",
    "                field=\"date\"  # Campo de partici√≥n\n",
    "            )\n",
    "        )\n",
    "\n",
    "        load_job = client.load_table_from_uri(\n",
    "            uri, table_id, job_config=job_config\n",
    "        )\n",
    "\n",
    "        print(f'Starting job {load_job.job_id}')\n",
    "        load_job.result()\n",
    "        print(f'Job finished.')\n",
    "\n",
    "        destination_table = client.get_table(table_id)\n",
    "        print(f'Loaded {destination_table.num_rows} rows.')\n",
    "```\n",
    "##### An√°lisis\n",
    "Se define funci√≥n que permite ejecutar la consulta en bigquery.\n",
    "\n",
    "```python\n",
    "    # Se define funci√≥n para ejecutar una consulta en BigQuery\n",
    "    def run_bigquery_query(query: str):\n",
    "        client = get_bigquery_client()\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "        return results\n",
    "```\n",
    "Se define la query SQL que permite ejecutar la consulta en bigquery.\n",
    "La lista de emojis se obtiene de https://gist.github.com/bfeldman89/fb25ddb63bdaa6de6ab7ac946acde96f#file-emojis-csv .\n",
    "```python\n",
    "    query = \"\"\"\n",
    "   WITH EmojiExtractor AS (\n",
    "    -- Separa todos los caracteres de cada tweet\n",
    "    SELECT\n",
    "        content,\n",
    "        SPLIT(content, '') AS chars\n",
    "    FROM\n",
    "        `project-latam-challenge.twitter_data.farmers_protest_tweets_2021`\n",
    "    ), EmojiCount AS (\n",
    "    -- Calcula la frecuencia de cada caracter\n",
    "    SELECT char,\n",
    "        COUNT(*) AS frequency\n",
    "    FROM EmojiExtractor\n",
    "    LEFT JOIN UNNEST(chars) AS char\n",
    "    WHERE\n",
    "    --LISTA DE POSIBLES EMOJIS\n",
    "        char IN (\n",
    "\"üòÄ\",\"üòÅ\",\"üòÇ\",\"ü§£\",\"üòÉ\",\"üòÑ\",\"üòÖ\",\"üòÜ\",\"üòâ\",\"üòä\",\"üòã\",\"üòé\",\"üòç\",\"üòò\",\"üòó\",\"üòô\",\"üòö\",\"‚ò∫\",\"üôÇ\",\"ü§ó\",\"ü§©\",\"ü§î\",\"ü§®\",\"üòê\",\"üòë\",\"üò∂\",\"üôÑ\",\"üòè\",\"üò£\",\"üò•\",\"üòÆ\",\"ü§ê\",\"üòØ\",\"üò™\",\"üò´\",\"üò¥\",\"üòå\",\"üòõ\",\"üòú\",\"üòù\",\"ü§§\",\"üòí\",\"üòì\",\"üòî\",\"üòï\",\"üôÉ\",\"ü§ë\",\"üò≤\",\"‚òπ\",\"üôÅ\",\"üòñ\",\"üòû\",\"üòü\",\"üò§\",\"üò¢\",\"üò≠\",\"üò¶\",\"üòß\",\"üò®\",\"üò©\",\"ü§Ø\",\"üò¨\",\"üò∞\",\"üò±\",\"üò≥\",\"ü§™\",\"üòµ\",\"üò°\",\"üò†\",\"ü§¨\",\"üò∑\",\"ü§í\",\"ü§ï\",\"ü§¢\",\"ü§Æ\",\"ü§ß\",\"üòá\",\"ü§†\",\"ü§°\",\"ü§•\",\"ü§´\",\"ü§≠\",\"üßê\",\"ü§ì\",\"üòà\",\"üëø\",\"üëπ\",\"üë∫\",\"üíÄ\",\"üëª\",\"üëΩ\",\"ü§ñ\",\"üí©\",\"üò∫\",\"üò∏\",\"üòπ\",\"üòª\",\"üòº\",\"üòΩ\",\"üôÄ\",\"üòø\",\"üòæ\",\"üë∂\",\"üë¶\",\"üëß\",\"üë®\",\"üë©\",\"üë¥\",\"üëµ\",\"üë®‚Äç‚öïÔ∏è\",\"üë©‚Äç‚öïÔ∏è\",\"üë®‚Äçüéì\",\"üë©‚Äçüéì\",\"üë®‚Äç‚öñÔ∏è\",\"üë©‚Äç‚öñÔ∏è\",\"üë®‚Äçüåæ\",\"üë©‚Äçüåæ\",\"üë®‚Äçüç≥\",\"üë©‚Äçüç≥\",\"üë®‚Äçüîß\",\"üë©‚Äçüîß\",\"üë®‚Äçüè≠\",\"üë©‚Äçüè≠\",\"üë®‚Äçüíº\",\"üë©‚Äçüíº\",\"üë®‚Äçüî¨\",\"üë©‚Äçüî¨\",\"üë®‚Äçüíª\",\"üë©‚Äçüíª\",\"üë®‚Äçüé§\",\"üë©‚Äçüé§\",\"üë®‚Äçüé®\",\"üë©‚Äçüé®\",\"üë®‚Äç‚úàÔ∏è\",\"üë©‚Äç‚úàÔ∏è\",\"üë®‚ÄçüöÄ\",\"üë©‚ÄçüöÄ\",\"üë®‚Äçüöí\",\"üë©‚Äçüöí\",\"üëÆ\",\"üëÆ‚Äç‚ôÇÔ∏è\",\"üëÆ‚Äç‚ôÄÔ∏è\",\"üïµ\",\"üïµÔ∏è‚Äç‚ôÇÔ∏è\",\"üïµÔ∏è‚Äç‚ôÄÔ∏è\",\"üíÇ\",\"üíÇ‚Äç‚ôÇÔ∏è\",\"üíÇ‚Äç‚ôÄÔ∏è\",\"üë∑\",\"üë∑‚Äç‚ôÇÔ∏è\",\"üë∑‚Äç‚ôÄÔ∏è\",\"ü§¥\",\"üë∏\",\"üë≥\",\"üë≥‚Äç‚ôÇÔ∏è\",\"üë≥‚Äç‚ôÄÔ∏è\",\"üë≤\",\"üßï\",\"üßî\",\"üë±\",\"üë±‚Äç‚ôÇÔ∏è\",\"üë±‚Äç‚ôÄÔ∏è\",\"ü§µ\",\"üë∞\",\"ü§∞\",\"ü§±\",\"üëº\",\"üéÖ\",\"ü§∂\",\"üßô‚Äç‚ôÄÔ∏è\",\"üßô‚Äç‚ôÇÔ∏è\",\"üßö‚Äç‚ôÄÔ∏è\",\"üßö‚Äç‚ôÇÔ∏è\",\"üßõ‚Äç‚ôÄÔ∏è\",\"üßõ‚Äç‚ôÇÔ∏è\",\"üßú‚Äç‚ôÄÔ∏è\",\"üßú‚Äç‚ôÇÔ∏è\",\"üßù‚Äç‚ôÄÔ∏è\",\"üßù‚Äç‚ôÇÔ∏è\",\"üßû‚Äç‚ôÄÔ∏è\",\"üßû‚Äç‚ôÇÔ∏è\",\"üßü‚Äç‚ôÄÔ∏è\",\"üßü‚Äç‚ôÇÔ∏è\",\"üôç\",\"üôç‚Äç‚ôÇÔ∏è\",\"üôç‚Äç‚ôÄÔ∏è\",\"üôé\",\"üôé‚Äç‚ôÇÔ∏è\",\"üôé‚Äç‚ôÄÔ∏è\",\"üôÖ\",\"üôÖ‚Äç‚ôÇÔ∏è\",\"üôÖ‚Äç‚ôÄÔ∏è\",\"üôÜ\",\"üôÜ‚Äç‚ôÇÔ∏è\",\"üôÜ‚Äç‚ôÄÔ∏è\",\"üíÅ\",\"üíÅ‚Äç‚ôÇÔ∏è\",\"üíÅ‚Äç‚ôÄÔ∏è\",\"üôã\",\"üôã‚Äç‚ôÇÔ∏è\",\"üôã‚Äç‚ôÄÔ∏è\",\"üôá\",\"üôá‚Äç‚ôÇÔ∏è\",\"üôá‚Äç‚ôÄÔ∏è\",\"ü§¶\",\"ü§¶‚Äç‚ôÇÔ∏è\",\"ü§¶‚Äç‚ôÄÔ∏è\",\"ü§∑\",\"ü§∑‚Äç‚ôÇÔ∏è\",\"ü§∑‚Äç‚ôÄÔ∏è\",\"üíÜ\",\"üíÜ‚Äç‚ôÇÔ∏è\",\"üíÜ‚Äç‚ôÄÔ∏è\",\"üíá\",\"üíá‚Äç‚ôÇÔ∏è\",\"üíá‚Äç‚ôÄÔ∏è\",\"üö∂\",\"üö∂‚Äç‚ôÇÔ∏è\",\"üö∂‚Äç‚ôÄÔ∏è\",\"üèÉ\",\"üèÉ‚Äç‚ôÇÔ∏è\",\"üèÉ‚Äç‚ôÄÔ∏è\",\"üíÉ\",\"üï∫\",\"üëØ\",\"üëØ‚Äç‚ôÇÔ∏è\",\"üëØ‚Äç‚ôÄÔ∏è\",\"üßñ‚Äç‚ôÄÔ∏è\",\"üßñ‚Äç‚ôÇÔ∏è\",\"üï¥\",\"üó£\",\"üë§\",\"üë•\",\"üë´\",\"üë¨\",\"üë≠\",\"üíè\",\"üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®\",\"üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©\",\"üíë\",\"üë®‚Äç‚ù§Ô∏è‚Äçüë®\",\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\",\"üë™\",\"üë®‚Äçüë©‚Äçüë¶\",\"üë®‚Äçüë©‚Äçüëß\",\"üë®‚Äçüë©‚Äçüëß‚Äçüë¶\",\"üë®‚Äçüë©‚Äçüë¶‚Äçüë¶\",\"üë®‚Äçüë©‚Äçüëß‚Äçüëß\",\"üë®‚Äçüë®‚Äçüë¶\",\"üë®‚Äçüë®‚Äçüëß\",\"üë®‚Äçüë®‚Äçüëß‚Äçüë¶\",\"üë®‚Äçüë®‚Äçüë¶‚Äçüë¶\",\"üë®‚Äçüë®‚Äçüëß‚Äçüëß\",\"üë©‚Äçüë©‚Äçüë¶\",\"üë©‚Äçüë©‚Äçüëß\",\"üë©‚Äçüë©‚Äçüëß‚Äçüë¶\",\"üë©‚Äçüë©‚Äçüë¶‚Äçüë¶\",\"üë©‚Äçüë©‚Äçüëß‚Äçüëß\",\"üë®‚Äçüë¶\",\"üë®‚Äçüë¶‚Äçüë¶\",\"üë®‚Äçüëß\",\"üë®‚Äçüëß‚Äçüë¶\",\"üë®‚Äçüëß‚Äçüëß\",\"üë©‚Äçüë¶\",\"üë©‚Äçüë¶‚Äçüë¶\",\"üë©‚Äçüëß\",\"üë©‚Äçüëß‚Äçüë¶\",\"üë©‚Äçüëß‚Äçüëß\",\"ü§≥\",\"üí™\",\"üëà\",\"üëâ\",\"‚òù\",\"üëÜ\",\"üñï\",\"üëá\",\"‚úå\",\"ü§û\",\"üññ\",\"ü§ò\",\"üñê\",\"‚úã\",\"üëå\",\"üëç\",\"üëé\",\"‚úä\",\"üëä\",\"ü§õ\",\"ü§ú\",\"ü§ö\",\"üëã\",\"ü§ü\",\"‚úç\",\"üëè\",\"üëê\",\"üôå\",\"ü§≤\",\"üôè\",\"ü§ù\",\"üíÖ\",\"üëÇ\",\"üëÉ\",\"üë£\",\"üëÄ\",\"üëÅ\",\"üß†\",\"üëÖ\",\"üëÑ\",\"üíã\",\"üëì\",\"üï∂\",\"üëî\",\"üëï\",\"üëñ\",\"üß£\",\"üß§\",\"üß•\",\"üß¶\",\"üëó\",\"üëò\",\"üëô\",\"üëö\",\"üëõ\",\"üëú\",\"üëù\",\"üéí\",\"üëû\",\"üëü\",\"üë†\",\"üë°\",\"üë¢\",\"üëë\",\"üëí\",\"üé©\",\"üéì\",\"üß¢\",\"‚õë\",\"üíÑ\",\"üíç\",\"üåÇ\",\"‚òÇ\",\"üíº\",\"break\",\"üôà\",\"üôâ\",\"üôä\",\"üí•\",\"üí¶\",\"üí®\",\"üí´\",\"üêµ\",\"üêí\",\"ü¶ç\",\"üê∂\",\"üêï\",\"üê©\",\"üê∫\",\"ü¶ä\",\"üê±\",\"üêà\",\"ü¶Å\",\"üêØ\",\"üêÖ\",\"üêÜ\",\"üê¥\",\"üêé\",\"ü¶Ñ\",\"ü¶ì\",\"üêÆ\",\"üêÇ\",\"üêÉ\",\"üêÑ\",\"üê∑\",\"üêñ\",\"üêó\",\"üêΩ\",\"üêè\",\"üêë\",\"üêê\",\"üê™\",\"üê´\",\"ü¶í\",\"üêò\",\"ü¶è\",\"üê≠\",\"üêÅ\",\"üêÄ\",\"üêπ\",\"üê∞\",\"üêá\",\"üêø\",\"ü¶î\",\"ü¶á\",\"üêª\",\"üê®\",\"üêº\",\"üêæ\",\"ü¶É\",\"üêî\",\"üêì\",\"üê£\",\"üê§\",\"üê•\",\"üê¶\",\"üêß\",\"üïä\",\"ü¶Ö\",\"ü¶Ü\",\"ü¶â\",\"üê∏\",\"üêä\",\"üê¢\",\"ü¶é\",\"üêç\",\"üê≤\",\"üêâ\",\"ü¶ï\",\"ü¶ñ\",\"üê≥\",\"üêã\",\"üê¨\",\"üêü\",\"üê†\",\"üê°\",\"ü¶à\",\"üêô\",\"üêö\",\"ü¶Ä\",\"ü¶ê\",\"ü¶ë\",\"üêå\",\"ü¶ã\",\"üêõ\",\"üêú\",\"üêù\",\"üêû\",\"ü¶ó\",\"üï∑\",\"üï∏\",\"ü¶Ç\",\"üíê\",\"üå∏\",\"üíÆ\",\"üèµ\",\"üåπ\",\"ü•Ä\",\"üå∫\",\"üåª\",\"üåº\",\"üå∑\",\"üå±\",\"üå≤\",\"üå≥\",\"üå¥\",\"üåµ\",\"üåæ\",\"üåø\",\"‚òò\",\"üçÄ\",\"üçÅ\",\"üçÇ\",\"üçÉ\",\"üçÑ\",\"üå∞\",\"üåç\",\"üåé\",\"üåè\",\"üåê\",\"üåë\",\"üåí\",\"üåì\",\"üåî\",\"üåï\",\"üåñ\",\"üåó\",\"üåò\",\"üåô\",\"üåö\",\"üåõ\",\"üåú\",\"‚òÄ\",\"üåù\",\"üåû\",\"‚≠ê\",\"üåü\",\"üå†\",\"‚òÅ\",\"‚õÖ\",\"‚õà\",\"üå§\",\"üå•\",\"üå¶\",\"üåß\",\"üå®\",\"üå©\",\"üå™\",\"üå´\",\"üå¨\",\"üåà\",\"‚òÇ\",\"‚òî\",\"‚ö°\",\"‚ùÑ\",\"‚òÉ\",\"‚õÑ\",\"‚òÑ\",\"üî•\",\"üíß\",\"üåä\",\"üéÑ\",\"‚ú®\",\"üéã\",\"üéç\",\"break\",\"üçá\",\"üçà\",\"üçâ\",\"üçä\",\"üçã\",\"üçå\",\"üçç\",\"üçé\",\"üçè\",\"üçê\",\"üçë\",\"üçí\",\"üçì\",\"ü•ù\",\"üçÖ\",\"ü••\",\"ü•ë\",\"üçÜ\",\"ü•î\",\"ü•ï\",\"üåΩ\",\"üå∂\",\"ü•í\",\"ü•¶\",\"üçÑ\",\"ü•ú\",\"üå∞\",\"üçû\",\"ü•ê\",\"ü•ñ\",\"ü•®\",\"ü•û\",\"üßÄ\",\"üçñ\",\"üçó\",\"ü•©\",\"ü•ì\",\"üçî\",\"üçü\",\"üçï\",\"üå≠\",\"ü•™\",\"üåÆ\",\"üåØ\",\"üç≥\",\"üç≤\",\"ü•£\",\"ü•ó\",\"üçø\",\"ü•´\",\"üç±\",\"üçò\",\"üçô\",\"üçö\",\"üçõ\",\"üçú\",\"üçù\",\"üç†\",\"üç¢\",\"üç£\",\"üç§\",\"üç•\",\"üç°\",\"ü•ü\",\"ü•†\",\"ü•°\",\"üç¶\",\"üçß\",\"üç®\",\"üç©\",\"üç™\",\"üéÇ\",\"üç∞\",\"ü•ß\",\"üç´\",\"üç¨\",\"üç≠\",\"üçÆ\",\"üçØ\",\"üçº\",\"ü•õ\",\"‚òï\",\"üçµ\",\"üç∂\",\"üçæ\",\"üç∑\",\"üç∏\",\"üçπ\",\"üç∫\",\"üçª\",\"ü•Ç\",\"ü•É\",\"ü•§\",\"ü•¢\",\"üçΩ\",\"üç¥\",\"ü•Ñ\",\"break\",\"üëæ\",\"üßó‚Äç‚ôÄÔ∏è\",\"üßó‚Äç‚ôÇÔ∏è\",\"üßò‚Äç‚ôÄÔ∏è\",\"üßò‚Äç‚ôÇÔ∏è\",\"üï¥\",\"üèá\",\"‚õ∑\",\"üèÇ\",\"üèå\",\"üèåÔ∏è‚Äç‚ôÇÔ∏è\",\"üèåÔ∏è‚Äç‚ôÄÔ∏è\",\"üèÑ\",\"üèÑ‚Äç‚ôÇÔ∏è\",\"üèÑ‚Äç‚ôÄÔ∏è\",\"üö£\",\"üö£‚Äç‚ôÇÔ∏è\",\"üö£‚Äç‚ôÄÔ∏è\",\"üèä\",\"üèä‚Äç‚ôÇÔ∏è\",\"üèä‚Äç‚ôÄÔ∏è\",\"‚õπ\",\"‚õπÔ∏è‚Äç‚ôÇÔ∏è\",\"‚õπÔ∏è‚Äç‚ôÄÔ∏è\",\"üèã\",\"üèãÔ∏è‚Äç‚ôÇÔ∏è\",\"üèãÔ∏è‚Äç‚ôÄÔ∏è\",\"üö¥\",\"üö¥‚Äç‚ôÇÔ∏è\",\"üö¥‚Äç‚ôÄÔ∏è\",\"üöµ\",\"üöµ‚Äç‚ôÇÔ∏è\",\"üöµ‚Äç‚ôÄÔ∏è\",\"ü§∏\",\"ü§∏‚Äç‚ôÇÔ∏è\",\"ü§∏‚Äç‚ôÄÔ∏è\",\"ü§º\",\"ü§º‚Äç‚ôÇÔ∏è\",\"ü§º‚Äç‚ôÄÔ∏è\",\"ü§Ω\",\"ü§Ω‚Äç‚ôÇÔ∏è\",\"ü§Ω‚Äç‚ôÄÔ∏è\",\"ü§æ\",\"ü§æ‚Äç‚ôÇÔ∏è\",\"ü§æ‚Äç‚ôÄÔ∏è\",\"ü§π\",\"ü§π‚Äç‚ôÇÔ∏è\",\"ü§π‚Äç‚ôÄÔ∏è\",\"üé™\",\"üéó\",\"üéü\",\"üé´\",\"üéñ\",\"üèÜ\",\"üèÖ\",\"ü•á\",\"ü•à\",\"ü•â\",\"‚öΩ\",\"‚öæ\",\"üèÄ\",\"üèê\",\"üèà\",\"üèâ\",\"üéæ\",\"üé≥\",\"üèè\",\"üèë\",\"üèí\",\"üèì\",\"üè∏\",\"ü•ä\",\"ü•ã\",\"‚õ≥\",\"‚õ∏\",\"üé£\",\"üéΩ\",\"üéø\",\"üõ∑\",\"ü•å\",\"üéØ\",\"üé±\",\"üéÆ\",\"üé∞\",\"üé≤\",\"üé≠\",\"üé®\",\"üéº\",\"üé§\",\"üéß\",\"üé∑\",\"üé∏\",\"üéπ\",\"üé∫\",\"üéª\",\"ü•Å\",\"üé¨\",\"üèπ\",\"break\",\"üö£\",\"üèé\",\"üèç\",\"üóæ\",\"üèî\",\"‚õ∞\",\"üåã\",\"üóª\",\"üèï\",\"üèñ\",\"üèú\",\"üèù\",\"üèû\",\"üèü\",\"üèõ\",\"üèó\",\"üèò\",\"üèö\",\"üè†\",\"üè°\",\"üè¢\",\"üè£\",\"üè§\",\"üè•\",\"üè¶\",\"üè®\",\"üè©\",\"üè™\",\"üè´\",\"üè¨\",\"üè≠\",\"üèØ\",\"üè∞\",\"üíí\",\"üóº\",\"üóΩ\",\"‚õ™\",\"üïå\",\"üïç\",\"‚õ©\",\"üïã\",\"‚õ≤\",\"‚õ∫\",\"üåÅ\",\"üåÉ\",\"üèô\",\"üåÑ\",\"üåÖ\",\"üåÜ\",\"üåá\",\"üåâ\",\"üåå\",\"üé†\",\"üé°\",\"üé¢\",\"üöÇ\",\"üöÉ\",\"üöÑ\",\"üöÖ\",\"üöÜ\",\"üöá\",\"üöà\",\"üöâ\",\"üöä\",\"üöù\",\"üöû\",\"üöã\",\"üöå\",\"üöç\",\"üöé\",\"üöê\",\"üöë\",\"üöí\",\"üöì\",\"üöî\",\"üöï\",\"üöñ\",\"üöó\",\"üöò\",\"üöö\",\"üöõ\",\"üöú\",\"üö≤\",\"üõ¥\",\"üõµ\",\"üöè\",\"üõ§\",\"‚õΩ\",\"üö®\",\"üö•\",\"üö¶\",\"üöß\",\"‚öì\",\"‚õµ\",\"üö§\",\"üõ≥\",\"‚õ¥\",\"üõ•\",\"üö¢\",\"‚úà\",\"üõ©\",\"üõ´\",\"üõ¨\",\"üí∫\",\"üöÅ\",\"üöü\",\"üö†\",\"üö°\",\"üõ∞\",\"üöÄ\",\"üõ∏\",\"üå†\",\"‚õ±\",\"üéÜ\",\"üéá\",\"üéë\",\"üí¥\",\"üíµ\",\"üí∂\",\"üí∑\",\"üóø\",\"üõÇ\",\"üõÉ\",\"üõÑ\",\"üõÖ\",\"break\",\"‚ò†\",\"üõÄ\",\"üõå\",\"üíå\",\"üí£\",\"üï≥\",\"üõç\",\"üìø\",\"üíé\",\"üî™\",\"üè∫\",\"üó∫\",\"üíà\",\"üõ¢\",\"üõé\",\"‚åõ\",\"‚è≥\",\"‚åö\",\"‚è∞\",\"‚è±\",\"‚è≤\",\"üï∞\",\"üå°\",\"‚õ±\",\"üéà\",\"üéâ\",\"üéä\",\"üéé\",\"üéè\",\"üéê\",\"üéÄ\",\"üéÅ\",\"üîÆ\",\"üïπ\",\"üñº\",\"üìØ\",\"üéô\",\"üéö\",\"üéõ\",\"üìª\",\"üì±\",\"üì≤\",\"‚òé\",\"üìû\",\"üìü\",\"üì†\",\"üîã\",\"üîå\",\"üíª\",\"üñ•\",\"üñ®\",\"‚å®\",\"üñ±\",\"üñ≤\",\"üíΩ\",\"üíæ\",\"üíø\",\"üìÄ\",\"üé•\",\"üéû\",\"üìΩ\",\"üì∫\",\"üì∑\",\"üì∏\",\"üìπ\",\"üìº\",\"üîç\",\"üîé\",\"üïØ\",\"üí°\",\"üî¶\",\"üèÆ\",\"üìî\",\"üìï\",\"üìñ\",\"üìó\",\"üìò\",\"üìô\",\"üìö\",\"üìì\",\"üìÉ\",\"üìú\",\"üìÑ\",\"üì∞\",\"üóû\",\"üìë\",\"üîñ\",\"üè∑\",\"üí∞\",\"üí¥\",\"üíµ\",\"üí∂\",\"üí∑\",\"üí∏\",\"üí≥\",\"‚úâ\",\"üìß\",\"üì®\",\"üì©\",\"üì§\",\"üì•\",\"üì¶\",\"üì´\",\"üì™\",\"üì¨\",\"üì≠\",\"üìÆ\",\"üó≥\",\"‚úè\",\"‚úí\",\"üñã\",\"üñä\",\"üñå\",\"üñç\",\"üìù\",\"üìÅ\",\"üìÇ\",\"üóÇ\",\"üìÖ\",\"üìÜ\",\"üóí\",\"üóì\",\"üìá\",\"üìà\",\"üìâ\",\"üìä\",\"üìã\",\"üìå\",\"üìç\",\"üìé\",\"üñá\",\"üìè\",\"üìê\",\"‚úÇ\",\"üóÉ\",\"üóÑ\",\"üóë\",\"üîí\",\"üîì\",\"üîè\",\"üîê\",\"üîë\",\"üóù\",\"üî®\",\"‚õè\",\"‚öí\",\"üõ†\",\"üó°\",\"‚öî\",\"üî´\",\"üõ°\",\"üîß\",\"üî©\",\"‚öô\",\"üóú\",\"‚öñ\",\"üîó\",\"‚õì\",\"‚öó\",\"üî¨\",\"üî≠\",\"üì°\",\"üíâ\",\"üíä\",\"üö™\",\"üõè\",\"üõã\",\"üöΩ\",\"üöø\",\"üõÅ\",\"üö¨\",\"‚ö∞\",\"‚ö±\",\"üóø\",\"üö∞\",\"break\",\"üëÅÔ∏è‚Äçüó®Ô∏è\",\"üíò\",\"‚ù§\",\"üíì\",\"üíî\",\"üíï\",\"üíñ\",\"üíó\",\"üíô\",\"üíö\",\"üíõ\",\"üß°\",\"üíú\",\"üñ§\",\"üíù\",\"üíû\",\"üíü\",\"‚ù£\",\"üí§\",\"üí¢\",\"üí¨\",\"üóØ\",\"üí≠\",\"üíÆ\",\"‚ô®\",\"üíà\",\"üõë\",\"üïõ\",\"üïß\",\"üïê\",\"üïú\",\"üïë\",\"üïù\",\"üïí\",\"üïû\",\"üïì\",\"üïü\",\"üïî\",\"üï†\",\"üïï\",\"üï°\",\"üïñ\",\"üï¢\",\"üïó\",\"üï£\",\"üïò\",\"üï§\",\"üïô\",\"üï•\",\"üïö\",\"üï¶\",\"üåÄ\",\"‚ô†\",\"‚ô•\",\"‚ô¶\",\"‚ô£\",\"üÉè\",\"üÄÑ\",\"üé¥\",\"üîá\",\"üîà\",\"üîâ\",\"üîä\",\"üì¢\",\"üì£\",\"üìØ\",\"üîî\",\"üîï\",\"üéµ\",\"üé∂\",\"üèß\",\"üöÆ\",\"üö∞\",\"‚ôø\",\"üöπ\",\"üö∫\",\"üöª\",\"üöº\",\"üöæ\",\"‚ö†\",\"üö∏\",\"‚õî\",\"üö´\",\"üö≥\",\"üö≠\",\"üöØ\",\"üö±\",\"üö∑\",\"üîû\",\"‚ò¢\",\"‚ò£\",\"‚¨Ü\",\"‚Üó\",\"‚û°\",\"‚Üò\",\"‚¨á\",\"‚Üô\",\"‚¨Ö\",\"‚Üñ\",\"‚Üï\",\"‚Üî\",\"‚Ü©\",\"‚Ü™\",\"‚§¥\",\"‚§µ\",\"üîÉ\",\"üîÑ\",\"üîô\",\"üîö\",\"üîõ\",\"üîú\",\"üîù\",\"üõê\",\"‚öõ\",\"üïâ\",\"‚ú°\",\"‚ò∏\",\"‚òØ\",\"‚úù\",\"‚ò¶\",\"‚ò™\",\"‚òÆ\",\"üïé\",\"üîØ\",\"‚ôà\",\"‚ôâ\",\"‚ôä\",\"‚ôã\",\"‚ôå\",\"‚ôç\",\"‚ôé\",\"‚ôè\",\"‚ôê\",\"‚ôë\",\"‚ôí\",\"‚ôì\",\"‚õé\",\"üîÄ\",\"üîÅ\",\"üîÇ\",\"‚ñ∂\",\"‚è©\",\"‚óÄ\",\"‚è™\",\"üîº\",\"‚è´\",\"üîΩ\",\"‚è¨\",\"‚èπ\",\"‚èè\",\"üé¶\",\"üîÖ\",\"üîÜ\",\"üì∂\",\"üì≥\",\"üì¥\",\"‚ôª\",\"üî±\",\"üìõ\",\"üî∞\",\"‚≠ï\",\"‚úÖ\",\"‚òë\",\"‚úî\",\"‚úñ\",\"‚ùå\",\"‚ùé\",\"‚ûï\",\"‚ûñ\",\"‚ûó\",\"‚û∞\",\"‚ûø\",\"„ÄΩ\",\"‚ú≥\",\"‚ú¥\",\"‚ùá\",\"‚Äº\",\"‚Åâ\",\"‚ùì\",\"‚ùî\",\"‚ùï\",\"‚ùó\",\"¬©\",\"¬Æ\",\"‚Ñ¢\",\"Ô∏è‚É£\",\"0Ô∏è‚É£\",\"1Ô∏è‚É£\",\"2Ô∏è‚É£\",\"3Ô∏è‚É£\",\"4Ô∏è‚É£\",\"5Ô∏è‚É£\",\"6Ô∏è‚É£\",\"7Ô∏è‚É£\",\"8Ô∏è‚É£\",\"9Ô∏è‚É£\",\"üîü\",\"üíØ\",\"üî†\",\"üî°\",\"üî¢\",\"üî£\",\"üî§\",\"üÖ∞\",\"üÜé\",\"üÖ±\",\"üÜë\",\"üÜí\",\"üÜì\",\"‚Ñπ\",\"üÜî\",\"‚ìÇ\",\"üÜï\",\"üÜñ\",\"üÖæ\",\"üÜó\",\"üÖø\",\"üÜò\",\"üÜô\",\"üÜö\",\"üàÅ\",\"üàÇ\",\"üà∑\",\"üà∂\",\"üàØ\",\"üâê\",\"üàπ\",\"üàö\",\"üà≤\",\"üâë\",\"üà∏\",\"üà¥\",\"üà≥\",\"„äó\",\"„äô\",\"üà∫\",\"üàµ\",\"‚ñ™\",\"‚ñ´\",\"‚óª\",\"‚óº\",\"‚óΩ\",\"‚óæ\",\"‚¨õ\",\"‚¨ú\",\"üî∂\",\"üî∑\",\"üî∏\",\"üîπ\",\"üî∫\",\"üîª\",\"üí†\",\"üî≤\",\"üî≥\",\"‚ö™\",\"‚ö´\",\"üî¥\",\"üîµ\",\"break\",\"üèÅ\",\"üö©\",\"üéå\",\"üè¥\",\"üè≥\",\"üè≥Ô∏è‚Äçüåà\",\"üè¥‚Äç‚ò†Ô∏è\",\"üá¶üá®\",\"üá¶üá©\",\"üá¶üá™\",\"üá¶üá´\",\"üá¶üá¨\",\"üá¶üáÆ\",\"üá¶üá±\",\"üá¶üá≤\",\"üá¶üá¥\",\"üá¶üá∂\",\"üá¶üá∑\",\"üá¶üá∏\",\"üá¶üáπ\",\"üá¶üá∫\",\"üá¶üáº\",\"üá¶üáΩ\",\"üá¶üáø\",\"üáßüá¶\",\"üáßüáß\",\"üáßüá©\",\"üáßüá™\",\"üáßüá´\",\"üáßüá¨\",\"üáßüá≠\",\"üáßüáÆ\",\"üáßüáØ\",\"üáßüá±\",\"üáßüá≤\",\"üáßüá≥\",\"üáßüá¥\",\"üáßüá∂\",\"üáßüá∑\",\"üáßüá∏\",\"üáßüáπ\",\"üáßüáª\",\"üáßüáº\",\"üáßüáæ\",\"üáßüáø\",\"üá®üá¶\",\"üá®üá®\",\"üá®üá©\",\"üá®üá´\",\"üá®üá¨\",\"üá®üá≠\",\"üá®üáÆ\",\"üá®üá∞\",\"üá®üá±\",\"üá®üá≤\",\"üá®üá≥\",\"üá®üá¥\",\"üá®üáµ\",\"üá®üá∑\",\"üá®üá∫\",\"üá®üáª\",\"üá®üáº\",\"üá®üáΩ\",\"üá®üáæ\",\"üá®üáø\",\"üá©üá™\",\"üá©üá¨\",\"üá©üáØ\",\"üá©üá∞\",\"üá©üá≤\",\"üá©üá¥\",\"üá©üáø\",\"üá™üá¶\",\"üá™üá®\",\"üá™üá™\",\"üá™üá¨\",\"üá™üá≠\",\"üá™üá∑\",\"üá™üá∏\",\"üá™üáπ\",\"üá™üá∫\",\"üá´üáÆ\",\"üá´üáØ\",\"üá´üá∞\",\"üá´üá≤\",\"üá´üá¥\",\"üá´üá∑\",\"üá¨üá¶\",\"üá¨üáß\",\"üá¨üá©\",\"üá¨üá™\",\"üá¨üá´\",\"üá¨üá¨\",\"üá¨üá≠\",\"üá¨üáÆ\",\"üá¨üá±\",\"üá¨üá≤\",\"üá¨üá≥\",\"üá¨üáµ\",\"üá¨üá∂\",\"üá¨üá∑\",\"üá¨üá∏\",\"üá¨üáπ\",\"üá¨üá∫\",\"üá¨üáº\",\"üá¨üáæ\",\"üá≠üá∞\",\"üá≠üá≤\",\"üá≠üá≥\",\"üá≠üá∑\",\"üá≠üáπ\",\"üá≠üá∫\",\"üáÆüá®\",\"üáÆüá©\",\"üáÆüá™\",\"üáÆüá±\",\"üáÆüá≤\",\"üáÆüá≥\",\"üáÆüá¥\",\"üáÆüá∂\",\"üáÆüá∑\",\"üáÆüá∏\",\"üáÆüáπ\",\"üáØüá™\",\"üáØüá≤\",\"üáØüá¥\",\"üáØüáµ\",\"üá∞üá™\",\"üá∞üá¨\",\"üá∞üá≠\",\"üá∞üáÆ\",\"üá∞üá≤\",\"üá∞üá≥\",\"üá∞üáµ\",\"üá∞üá∑\",\"üá∞üáº\",\"üá∞üáæ\",\"üá∞üáø\",\"üá±üá¶\",\"üá±üáß\",\"üá±üá®\",\"üá±üáÆ\",\"üá±üá∞\",\"üá±üá∑\",\"üá±üá∏\",\"üá±üáπ\",\"üá±üá∫\",\"üá±üáª\",\"üá±üáæ\",\"üá≤üá¶\",\"üá≤üá®\",\"üá≤üá©\",\"üá≤üá™\",\"üá≤üá´\",\"üá≤üá¨\",\"üá≤üá≠\",\"üá≤üá∞\",\"üá≤üá±\",\"üá≤üá≤\",\"üá≤üá≥\",\"üá≤üá¥\",\"üá≤üáµ\",\"üá≤üá∂\",\"üá≤üá∑\",\"üá≤üá∏\",\"üá≤üáπ\",\"üá≤üá∫\",\"üá≤üáª\",\"üá≤üáº\",\"üá≤üáΩ\",\"üá≤üáæ\",\"üá≤üáø\",\"üá≥üá¶\",\"üá≥üá®\",\"üá≥üá™\",\"üá≥üá´\",\"üá≥üá¨\",\"üá≥üáÆ\",\"üá≥üá±\",\"üá≥üá¥\",\"üá≥üáµ\",\"üá≥üá∑\",\"üá≥üá∫\",\"üá≥üáø\",\"üá¥üá≤\",\"üáµüá¶\",\"üáµüá™\",\"üáµüá´\",\"üáµüá¨\",\"üáµüá≠\",\"üáµüá∞\",\"üáµüá±\",\"üáµüá≤\",\"üáµüá≥\",\"üáµüá∑\",\"üáµüá∏\",\"üáµüáπ\",\"üáµüáº\",\"üáµüáæ\",\"üá∂üá¶\",\"üá∑üá™\",\"üá∑üá¥\",\"üá∑üá∏\",\"üá∑üá∫\",\"üá∑üáº\",\"üá∏üá¶\",\"üá∏üáß\",\"üá∏üá®\",\"üá∏üá©\",\"üá∏üá™\",\"üá∏üá¨\",\"üá∏üá≠\",\"üá∏üáÆ\",\"üá∏üáØ\",\"üá∏üá∞\",\"üá∏üá±\",\"üá∏üá≤\",\"üá∏üá≥\",\"üá∏üá¥\",\"üá∏üá∑\",\"üá∏üá∏\",\"üá∏üáπ\",\"üá∏üáª\",\"üá∏üáΩ\",\"üá∏üáæ\",\"üá∏üáø\",\"üáπüá¶\",\"üáπüá®\",\"üáπüá©\",\"üáπüá´\",\"üáπüá¨\",\"üáπüá≠\",\"üáπüáØ\",\"üáπüá∞\",\"üáπüá±\",\"üáπüá≤\",\"üáπüá≥\",\"üáπüá¥\",\"üáπüá∑\",\"üáπüáπ\",\"üáπüáª\",\"üáπüáº\",\"üáπüáø\",\"üá∫üá¶\",\"üá∫üá¨\",\"üá∫üá≤\",\"üá∫üá≥\",\"üá∫üá∏\",\"üá∫üáæ\",\"üá∫üáø\",\"üáªüá¶\",\"üáªüá®\",\"üáªüá™\",\"üáªüá¨\",\"üáªüáÆ\",\"üáªüá≥\",\"üáªüá∫\",\"üáºüá´\",\"üáºüá∏\",\"üáΩüá∞\",\"üáæüá™\",\"üáæüáπ\",\"üáøüá¶\",\"üáøüá≤\",\"üáøüáº\",\"üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\",\"üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø\",\"üè¥Û†ÅßÛ†Å¢Û†Å∑Û†Å¨Û†Å≥Û†Åø\"\n",
    "        )\n",
    "    GROUP BY char\n",
    "    )\n",
    "    SELECT char AS emoji,\n",
    "    frequency\n",
    "    FROM EmojiCount\n",
    "    ORDER BY frequency DESC\n",
    "    LIMIT 10\n",
    "        \"\"\"\n",
    "    \n",
    "    results = run_bigquery_query(query)\n",
    "    return [(row.fecha, row.username) for row in results]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso q1_time...\n",
      "Leyendo archivo JSON\n",
      "Creando bucket y subiendo archivo\n",
      "Bucket bucket-project-latam-challenge-q2-time created in location US.\n",
      "File farmers-protest-tweets-2021-2-4.json uploaded to bucket-project-latam-challenge-q2-time/farmers-protest-tweets-2021-2-4.json.\n",
      "Cargando datos a BigQuery\n",
      "Starting job 1333d214-6ca2-451e-b71b-4424be85fa81\n",
      "Job finished.\n",
      "Loaded 234814 rows.\n",
      "Ejecutando query\n",
      "Resultados:\n",
      "[('‚úä', 4822), ('‚ù§', 3558), ('‚òÆ', 632), ('‚úå', 548), ('‚Äº', 222), ('‚úç', 206), ('‚ô•', 162), ('‚õ≥', 136), ('‚úÖ', 114), ('‚û°', 112)]\n",
      "Tiempo de ejecuci√≥n: 51.47749996185303 segundos\n",
      "Uso m√°ximo de memoria: 2133.34765625 MiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from q2_time import q2_time\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../credentials/project-latam-challenge-749ce1a96052.json\"\n",
    "\n",
    "# Funci√≥n para medir el tiempo y la memoria de q2_time\n",
    "def measure_q1_time(file_path):\n",
    "    start_time = time.time()\n",
    "    mem_usage, result = memory_usage((q2_time, (file_path,)), retval=True, max_usage=True)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    return result, duration, mem_usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando proceso q1_time...\")\n",
    "    top_10_emojis, duration, mem_usage = measure_q1_time(file_path)\n",
    "    print(\"Resultados:\")\n",
    "    print(top_10_emojis)\n",
    "    print(f\"Tiempo de ejecuci√≥n: {duration} segundos\")\n",
    "    print(f\"Uso m√°ximo de memoria: {mem_usage} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREGUNTA 2 - MEMORY\n",
    "Se propone generar un proceso an√°logo al anteriormente realizado para la versi√≥n time, pero con una carga parcelada de forma que utilice menos memoria local y se ejecute con menor necesidad de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos. Debe incluir las siguientes funciones:\n",
    "```python\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "```\n",
    "```python\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "```\n",
    "```python\n",
    "Returns: \n",
    "[(\"LATAM321\", 387), (\"LATAM_CHI\", 129), ...]\n",
    "```\n",
    "‚Äã\n",
    "## PREGUNTA 3 - TIME (q3_time)\n",
    "Para desarrollar la soluci√≥n a este problema se utilizar√° una soluci√≥n cloud basada en Google Cloud Platform. La funci√≥n contendr√° el proceso de ETL para llevar los datos desde el archivo json local hacia Google Cloud Storage y posteriormente modelar esa data en una tabla de bigquery que permita realizar consultas de manera r√°pida y eficiente.\n",
    "### ETL\n",
    "El proceso de extracci√≥n, transformaci√≥n y carga de los archivos en GCP permite llevar los archivos a una plataforma de performance r√°pida y efectiva.\n",
    "#### Credenciales\n",
    "Este desarrollo se realizar√° utilizando Google Cloud, por lo que se crea un proyecto en GCP llamado \"project-latam-challenge\". En este proyecto se crea una service account llamada \"sa-etl-latam-challenge\" que ser√° utilizada para realizar la carga de datos.\n",
    "```python\n",
    "import os\n",
    "\n",
    "# Ruta a archivo de credenciales JSON de Google Cloud\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../credentials/project-latam-challenge-749ce1a96052.json\"\n",
    "```\n",
    "#### Carga en Dataframe\n",
    "Se carga en un dataframe el [archivo](https://drive.google.com/file/d/1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis/view?usp=sharing) json declarado como parte del challenge.\n",
    "```python\n",
    "    # Leer el archivo CSV en un DataFrame\n",
    "    df = pd.read_json(file_path,lines=True)\n",
    "```\n",
    "#### Carga de dataframe en GCP\n",
    "##### Carga de archivo en Google Cloud Storage (GCS)\n",
    "Usando Google Cloud SDK se crea un bucket llamado 'bucket-project-latam-challenge-q1-time' en el proyecto 'project-latam-challenge' y se carga el archivo directamente a dicho bucket.\n",
    "```python\n",
    "    # Se define funci√≥n que permite cargar un archivo en un bucket de Google Cloud Storage\n",
    "    def create_bucket_and_upload_file(project_id, bucket_name, file_path, destination_blob_name):\n",
    "        # Inicializar el cliente de almacenamiento\n",
    "        storage_client = storage.Client(project=project_id)\n",
    "        \n",
    "        # Verificar si el bucket ya existe\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        if not bucket.exists():\n",
    "            # Crear un nuevo bucket con la ubicaci√≥n especificada\n",
    "            new_bucket = storage_client.create_bucket(bucket, location=\"US\")\n",
    "            print(f'Bucket {bucket_name} created in location US.')\n",
    "        else:\n",
    "            print(f'Bucket {bucket_name} already exists.')\n",
    "            new_bucket = bucket\n",
    "        \n",
    "        # Subir el archivo al bucket\n",
    "        blob = new_bucket.blob(destination_blob_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        print(f'File {file_path} uploaded to {bucket_name}/{destination_blob_name}.')\n",
    "```\n",
    "##### Configuraci√≥n de carga\n",
    "```python\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Par√°metros\n",
    "project_id = 'project-latam-challenge'\n",
    "dataset_id = 'twitter_data'\n",
    "table_id = 'farmers_protest_tweets_2021'\n",
    "```\n",
    "##### Declaraci√≥n de schema\n",
    "Se declara explicitamente la estructura del esquema con la data correspondiente, esto permitir√° evitar errores en los tipos de dato al cargar la data en Bigquery.\n",
    "Por motivos de claridad al momento de leer el markdown, se omite el schema que se puede encontrar en el archivo q1_time.py .\n",
    "##### Proceso de creaci√≥n de tabla en bigquery\n",
    "```python\n",
    "    # Se define funci√≥n que crea tabla de bigquery a partir de archivo almacenado en GCS\n",
    "    def load_data_from_gcs_to_bigquery(uri, table_id):\n",
    "        # Inicializa el cliente de BigQuery\n",
    "        client = bigquery.Client()\n",
    "\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            schema=schema,\n",
    "            source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "            max_bad_records=0,  # No permitir registros malos antes de fallar\n",
    "            time_partitioning=bigquery.TimePartitioning(\n",
    "                type_=bigquery.TimePartitioningType.DAY,\n",
    "                field=\"date\"  # Campo de partici√≥n\n",
    "            )\n",
    "        )\n",
    "\n",
    "        load_job = client.load_table_from_uri(\n",
    "            uri, table_id, job_config=job_config\n",
    "        )\n",
    "\n",
    "        print(f'Starting job {load_job.job_id}')\n",
    "        load_job.result()\n",
    "        print(f'Job finished.')\n",
    "\n",
    "        destination_table = client.get_table(table_id)\n",
    "        print(f'Loaded {destination_table.num_rows} rows.')\n",
    "```\n",
    "##### An√°lisis\n",
    "Se define funci√≥n que permite ejecutar la consulta en bigquery.\n",
    "\n",
    "```python\n",
    "    # Se define funci√≥n para ejecutar una consulta en BigQuery\n",
    "    def run_bigquery_query(query: str):\n",
    "        client = get_bigquery_client()\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "        return results\n",
    "```\n",
    "Se define la query SQL que permite ejecutar la consulta en bigquery.\n",
    "La lista de emojis se obtiene de https://gist.github.com/bfeldman89/fb25ddb63bdaa6de6ab7ac946acde96f#file-emojis-csv .\n",
    "```python\n",
    "    query = \"\"\"\n",
    "        WITH TEMP_DATA_001 AS \n",
    "        (\n",
    "        SELECT mentionedUsers.username AS username\n",
    "            -- quotedTweet.mentionedUsers.username,\n",
    "            -- quotedTweet.quotedTweet.mentionedUsers.username,\n",
    "            -- quotedTweet.quotedTweet.quotedTweet.mentionedUsers.username\n",
    "        FROM `project-latam-challenge.twitter_data.farmers_protest_tweets_2021` \n",
    "        LEFT JOIN UNNEST(mentionedUsers) AS mentionedUsers\n",
    "        WHERE date is not null AND mentionedUsers.username IS NOT NULL\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT quotedTweet_mentionedUsers.username AS username\n",
    "            -- quotedTweet.quotedTweet.mentionedUsers.username,\n",
    "            -- quotedTweet.quotedTweet.quotedTweet.mentionedUsers.username\n",
    "        FROM `project-latam-challenge.twitter_data.farmers_protest_tweets_2021` \n",
    "        LEFT JOIN UNNEST(quotedTweet.mentionedUsers) AS quotedTweet_mentionedUsers\n",
    "        WHERE date is not null AND quotedTweet_mentionedUsers.username IS NOT NULL\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT quotedTweet_quotedTweet_mentionedUsers.username AS username\n",
    "            -- quotedTweet.quotedTweet.quotedTweet.mentionedUsers.username\n",
    "        FROM `project-latam-challenge.twitter_data.farmers_protest_tweets_2021` \n",
    "        LEFT JOIN UNNEST(quotedTweet.quotedTweet.mentionedUsers) AS quotedTweet_quotedTweet_mentionedUsers\n",
    "        WHERE date is not null AND quotedTweet_quotedTweet_mentionedUsers.username IS NOT NULL\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT quotedTweet_quotedTweet_quotedTweet_mentionedUsers.username AS username\n",
    "            -- quotedTweet.quotedTweet.quotedTweet.mentionedUsers.username\n",
    "        FROM `project-latam-challenge.twitter_data.farmers_protest_tweets_2021` \n",
    "        LEFT JOIN UNNEST(quotedTweet.quotedTweet.quotedTweet.mentionedUsers) AS quotedTweet_quotedTweet_quotedTweet_mentionedUsers\n",
    "        WHERE date is not null AND quotedTweet_quotedTweet_quotedTweet_mentionedUsers.username IS NOT NULL\n",
    "        )\n",
    "        SELECT username,\n",
    "        COUNT(*) AS frequency\n",
    "        FROM TEMP_DATA_001 A\n",
    "        GROUP BY ALL\n",
    "        ORDER BY frequency DESC\n",
    "        LIMIT 10\n",
    "        \"\"\"\n",
    "    \n",
    "    results = run_bigquery_query(query)\n",
    "    return [(row.fecha, row.username) for row in results]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso q1_time...\n",
      "Leyendo archivo JSON\n",
      "Creando bucket y subiendo archivo\n",
      "Bucket bucket-project-latam-challenge-q3-time created in location US.\n",
      "File farmers-protest-tweets-2021-2-4.json uploaded to bucket-project-latam-challenge-q3-time/farmers-protest-tweets-2021-2-4.json.\n",
      "Cargando datos a BigQuery\n",
      "Starting job 1796d4db-1b8c-4d54-a87d-27d18e14ae1b\n",
      "Job finished.\n",
      "Loaded 352221 rows.\n",
      "Ejecutando query\n",
      "Resultados:\n",
      "[('narendramodi', 7875), ('Kisanektamorcha', 6135), ('RakeshTikaitBKU', 5544), ('PMOIndia', 4686), ('GretaThunberg', 3939), ('RahulGandhi', 3756), ('rihanna', 3471), ('DelhiPolice', 3420), ('RaviSinghKA', 3381), ('UNHumanRights', 3180)]\n",
      "Tiempo de ejecuci√≥n: 50.49053502082825 segundos\n",
      "Uso m√°ximo de memoria: 2575.734375 MiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from q3_time import q3_time\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../credentials/project-latam-challenge-749ce1a96052.json\"\n",
    "\n",
    "# Funci√≥n para medir el tiempo y la memoria de q2_time\n",
    "def measure_q1_time(file_path):\n",
    "    start_time = time.time()\n",
    "    mem_usage, result = memory_usage((q3_time, (file_path,)), retval=True, max_usage=True)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    return result, duration, mem_usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando proceso q1_time...\")\n",
    "    top_10_users, duration, mem_usage = measure_q1_time(file_path)\n",
    "    print(\"Resultados:\")\n",
    "    print(top_10_users)\n",
    "    print(f\"Tiempo de ejecuci√≥n: {duration} segundos\")\n",
    "    print(f\"Uso m√°ximo de memoria: {mem_usage} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### CONCLUSI√ìN GENERAL\n",
    "GCP es una herramienta adecuada para la realizaci√≥n de este tipo de tareas, debido a que tiene bueno tiempos de respuesta, pese a un bajo uso de memoria local, esto se logra principalmente gracias a la infraestructura de procesamiento distribuido que utiliza Bigquery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
